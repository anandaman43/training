{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv1_1_W (3, 3, 3, 64)\n",
      "1 conv1_1_b (64,)\n",
      "2 conv1_2_W (3, 3, 64, 64)\n",
      "3 conv1_2_b (64,)\n",
      "4 conv2_1_W (3, 3, 64, 128)\n",
      "5 conv2_1_b (128,)\n",
      "6 conv2_2_W (3, 3, 128, 128)\n",
      "7 conv2_2_b (128,)\n",
      "8 conv3_1_W (3, 3, 128, 256)\n",
      "9 conv3_1_b (256,)\n",
      "10 conv3_2_W (3, 3, 256, 256)\n",
      "11 conv3_2_b (256,)\n",
      "12 conv3_3_W (3, 3, 256, 256)\n",
      "13 conv3_3_b (256,)\n",
      "14 conv4_1_W (3, 3, 256, 512)\n",
      "15 conv4_1_b (512,)\n",
      "16 conv4_2_W (3, 3, 512, 512)\n",
      "17 conv4_2_b (512,)\n",
      "18 conv4_3_W (3, 3, 512, 512)\n",
      "19 conv4_3_b (512,)\n",
      "20 conv5_1_W (3, 3, 512, 512)\n",
      "21 conv5_1_b (512,)\n",
      "22 conv5_2_W (3, 3, 512, 512)\n",
      "23 conv5_2_b (512,)\n",
      "24 conv5_3_W (3, 3, 512, 512)\n",
      "25 conv5_3_b (512,)\n",
      "26 fc6_W (25088, 4096)\n",
      "27 fc6_b (4096,)\n",
      "28 fc7_W (4096, 4096)\n",
      "29 fc7_b (4096,)\n",
      "30 fc8_W (4096, 1000)\n",
      "31 fc8_b (1000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:250: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:251: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "from imagenet_classes import class_names\n",
    "\n",
    "\n",
    "class vgg16:\n",
    "    def __init__(self, imgs, weights=None, sess=None):\n",
    "        self.imgs = imgs\n",
    "        self.convlayers()\n",
    "        self.fc_layers()\n",
    "        self.features = tf.nn.relu(self.fc3l)\n",
    "        if weights is not None and sess is not None:\n",
    "            self.load_weights(weights, sess)\n",
    "\n",
    "\n",
    "    def convlayers(self):\n",
    "        self.parameters = []\n",
    "\n",
    "        # zero-mean input\n",
    "        with tf.name_scope('preprocess') as scope:\n",
    "            mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean')\n",
    "            images = self.imgs-mean\n",
    "\n",
    "        # conv1_1\n",
    "        with tf.name_scope('conv1_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv1_2\n",
    "        with tf.name_scope('conv1_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv1_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool1\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool1')\n",
    "\n",
    "        # conv2_1\n",
    "        with tf.name_scope('conv2_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv2_2\n",
    "        with tf.name_scope('conv2_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv2_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool2\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool2')\n",
    "\n",
    "        # conv3_1\n",
    "        with tf.name_scope('conv3_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_2\n",
    "        with tf.name_scope('conv3_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv3_3\n",
    "        with tf.name_scope('conv3_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv3_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool3\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool3')\n",
    "\n",
    "        # conv4_1\n",
    "        with tf.name_scope('conv4_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_2\n",
    "        with tf.name_scope('conv4_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv4_3\n",
    "        with tf.name_scope('conv4_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv4_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool4\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "        # conv5_1\n",
    "        with tf.name_scope('conv5_1') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_1 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_2\n",
    "        with tf.name_scope('conv5_2') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_2 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # conv5_3\n",
    "        with tf.name_scope('conv5_3') as scope:\n",
    "            kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                                     stddev=1e-1), name='weights')\n",
    "            conv = tf.nn.conv2d(self.conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            out = tf.nn.bias_add(conv, biases)\n",
    "            self.conv5_3 = tf.nn.relu(out, name=scope)\n",
    "            self.parameters += [kernel, biases]\n",
    "\n",
    "        # pool5\n",
    "        self.pool5 = tf.nn.max_pool(self.conv5_3,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME',\n",
    "                               name='pool4')\n",
    "\n",
    "    def fc_layers(self):\n",
    "        # fc1\n",
    "        with tf.name_scope('fc1') as scope:\n",
    "            shape = int(np.prod(self.pool5.get_shape()[1:]))\n",
    "            fc1w = tf.Variable(tf.truncated_normal([shape, 4096],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc1b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            pool5_flat = tf.reshape(self.pool5, [-1, shape])\n",
    "            fc1l = tf.nn.bias_add(tf.matmul(pool5_flat, fc1w), fc1b)\n",
    "            self.fc1 = tf.nn.relu(fc1l)\n",
    "            self.parameters += [fc1w, fc1b]\n",
    "\n",
    "        # fc2\n",
    "        with tf.name_scope('fc2') as scope:\n",
    "            fc2w = tf.Variable(tf.truncated_normal([4096, 4096],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc2b = tf.Variable(tf.constant(1.0, shape=[4096], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            fc2l = tf.nn.bias_add(tf.matmul(self.fc1, fc2w), fc2b)\n",
    "            self.fc2 = tf.nn.relu(fc2l)\n",
    "            self.parameters += [fc2w, fc2b]\n",
    "\n",
    "        # fc3\n",
    "        with tf.name_scope('fc3') as scope:\n",
    "            fc3w = tf.Variable(tf.truncated_normal([4096, 1000],\n",
    "                                                         dtype=tf.float32,\n",
    "                                                         stddev=1e-1), name='weights')\n",
    "            fc3b = tf.Variable(tf.constant(1.0, shape=[1000], dtype=tf.float32),\n",
    "                                 trainable=True, name='biases')\n",
    "            self.fc3l = tf.nn.bias_add(tf.matmul(self.fc2, fc3w), fc3b)\n",
    "            self.parameters += [fc3w, fc3b]\n",
    "\n",
    "    def load_weights(self, weight_file, sess):\n",
    "        weights = np.load(weight_file)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            print i, k, np.shape(weights[k])\n",
    "            sess.run(self.parameters[i].assign(weights[k]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sess = tf.Session()\n",
    "    imgs = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    vgg = vgg16(imgs, 'vgg16_weights.npz', sess)\n",
    "\n",
    "    img1 = imread('laska.png', mode='RGB')\n",
    "    img1 = imresize(img1, (224, 224))\n",
    "\n",
    "    features = sess.run(vgg.features, feed_dict={vgg.imgs: [img1]})[0]\n",
    "    print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.6655338   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          2.059135    0.          0.856609\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.05613287  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.27716947  0.          0.35121012  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.1025593   1.3762869   0.7752596   1.2865803\n",
      "  0.2112316   0.          0.          0.22002943  9.562728    4.099201\n",
      "  0.91803026  3.603652    2.7122817   1.1100464   3.2753608   1.2261206\n",
      "  2.302006    8.269981   10.241667    0.          2.573897    2.759427\n",
      "  4.7087545   8.789814    4.3457737   7.7598963   1.7504704   0.\n",
      "  0.          3.4214342   2.2151172   1.1575994   5.2387204   0.9293382\n",
      "  0.85468864  0.          3.3751757   0.848863    1.9774503   2.657493\n",
      "  2.4257483   0.978943    0.9479158   0.9037883   0.4728784   3.976489\n",
      "  1.9890382   2.4961696   5.7746873   0.          8.129856    4.0892005\n",
      "  2.943378    4.519677    3.5130537   8.720874    5.104418    3.2583838\n",
      "  0.80628115  0.30220318  7.386925    3.0908308   5.0839295   2.3386497\n",
      "  3.391793    4.1131225   2.8074071   4.0148816   4.0321565   2.2248073\n",
      " 13.382649    1.3773421   3.986304    2.0760808   7.238236    3.7533076\n",
      "  9.239881   10.726091    3.528864    6.600391    6.6053886   5.214977\n",
      "  1.0187314   6.395229    2.8428364   0.          4.044227    5.5811586\n",
      "  3.6546385   3.1579044   0.          1.1341761   8.405536    0.\n",
      "  4.1874943   7.2179103   7.9277215   8.454148    6.9316564   5.8616843\n",
      "  0.19593418  0.          1.2212212   6.3942814   8.720253   13.483765\n",
      "  8.322208    0.          3.0969942   3.1992607   0.          1.6320974\n",
      "  2.0563421   0.79902256  0.87401533  6.877236    0.          5.818679\n",
      "  9.250157    1.1940225   2.5613816   2.4096112   0.          0.\n",
      "  1.3623792   0.          0.          2.7276888   0.          0.\n",
      "  0.30982038  0.27930018  0.          0.90214133  0.          0.\n",
      "  0.          0.          0.          0.06547435  1.3412324   0.\n",
      "  2.2443883   0.57245165  7.2074223   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.20457347\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.5982812   0.          0.\n",
      "  0.1245116   0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          2.3061078   0.          0.\n",
      "  5.0744486   0.          0.          0.          0.          0.\n",
      "  0.24333966  6.4183784   1.022504    0.          0.91053843  1.7945937\n",
      "  0.60667723  0.56313294  0.6110242   0.          0.          0.\n",
      "  0.          0.          0.67285115  0.          0.          0.\n",
      "  0.6519289   0.10700838  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.01982865  0.          0.93982327  0.\n",
      "  0.          1.7060881   0.          0.          1.7385726   0.\n",
      "  0.          0.          0.          0.11235894  0.          0.87958556\n",
      "  0.          0.          0.1179156   1.0502222   0.          2.2763867\n",
      "  0.1597288   5.7498913   0.          0.85807866  5.2292457   0.\n",
      "  0.          0.1234234   1.0288979   1.698319    2.8649344   0.\n",
      "  0.          3.1276023   0.          0.          0.          0.\n",
      "  4.8816805   1.3470546   2.911412    0.          1.4256363   2.749952\n",
      "  0.85160017  0.          5.418542    1.6165833   0.42885798  0.999166\n",
      "  0.          2.2341907   0.          0.62758857  2.5895758   0.\n",
      "  3.3649738   0.08583903  0.          2.0920749   0.786471    0.11808427\n",
      "  2.1965423   0.          1.1263741   0.          0.          0.\n",
      "  1.4781501   0.0782742   0.          0.          1.7658932   0.\n",
      "  3.0660288   4.1950526   0.          0.          0.2436048   0.40155983\n",
      "  1.9737067   0.          0.5401718   1.0318449   3.8102207   0.\n",
      "  0.7016686   0.2864923   0.          0.12641424  0.37735558  3.411532\n",
      "  4.6454167   2.253075    2.9256258   0.          1.503079    1.2721307\n",
      "  0.          4.321595    0.          3.0736837   0.          1.3221796\n",
      "  0.          0.          0.68792665  0.          3.7916148   0.\n",
      "  0.9024017   1.9820321   0.          2.5672998   3.289709    0.5975951\n",
      "  0.8657617   0.16925533  0.          1.5723051   0.          0.\n",
      "  0.          1.6061355   0.          0.          1.4882512   1.5954084\n",
      "  0.          0.          0.89592224  2.4219942   0.          0.\n",
      "  1.6674869   2.5434504   0.          1.4059354   0.          0.\n",
      "  3.7384274   0.          4.370138    4.4927273   0.          0.2907411\n",
      "  4.1536016   1.5418859   0.          4.727682    0.          5.699285\n",
      "  0.          0.7587436   0.5049186   0.          0.          1.8741236\n",
      "  0.          0.          0.          0.          0.          0.46099687\n",
      "  3.9237077   0.          2.185253    0.          0.          0.72525537\n",
      "  1.0060931   0.5317478   0.          1.2698904   1.0714419   0.02260426\n",
      "  0.          0.          0.          0.          7.2390194   0.32510453\n",
      "  0.          3.807304    0.          0.5502287   0.          0.\n",
      "  0.          0.8129318   1.7856715   0.          0.          0.\n",
      "  0.          0.          0.          1.7517734   0.          3.3119264\n",
      "  1.4031985   6.0083265   1.4817913   0.9387846   0.          0.88819253\n",
      "  2.7263217   0.          2.8734486   0.          0.          0.\n",
      "  1.1023803   1.0927658   0.7452919   1.0469744   0.          1.8015842\n",
      "  1.7776879   0.          2.8940084   2.7824414   1.2367916   0.\n",
      "  0.          1.3197532   0.94358206  1.9489737   0.5716232   2.089489\n",
      "  0.          0.5970856   1.0729859   1.1784959   0.          0.\n",
      "  0.          1.3948052   3.0808854   1.7199341   0.          1.7062447\n",
      "  0.          0.31977487  1.027882    0.          0.          2.1682537\n",
      "  0.          2.5012524   0.18797721  0.          0.8331346   0.\n",
      "  0.          0.8825037   0.          0.          0.30801427  0.31145\n",
      "  0.          0.          2.828809    0.87114555  0.          0.34485966\n",
      "  1.494356    2.0588899   2.2524116   0.894985    1.3498415   0.\n",
      "  1.359484    0.          0.8004755   0.          1.6404582   2.2210774\n",
      "  0.          0.8687921   0.          0.58613896  0.8614179   2.4277015\n",
      "  0.3135514   1.0626516   0.          1.206483    5.2284613   0.\n",
      "  1.6487744   0.          0.36266315  0.31225944  0.          0.\n",
      "  0.8465283   1.9873813   2.1833742   0.          1.1805944   0.46027017\n",
      "  0.1393653   0.05461463  0.          2.6290078   0.          0.\n",
      "  1.6757532   4.143227    0.          3.0122266   4.1018863   1.1655105\n",
      "  0.39774647  0.58408535  2.0261178   2.1248446   0.          5.4112854\n",
      "  2.1240342   0.483397    1.4704822   0.          0.          0.\n",
      "  0.          0.          1.1107657   0.7082052   1.6880038   0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.7558265   0.          0.          1.68366\n",
      "  0.          2.5572348   0.72745824  3.2801247   0.2929209   0.\n",
      "  0.          0.07090113  2.8725507   0.          0.9924269   0.\n",
      "  0.          0.          0.8629672   3.7507725   0.10982521  0.\n",
      "  0.23478013  1.3914422   2.9790754   1.8189089   3.283241    1.53712\n",
      "  2.5441449   1.8223363   0.45692325  0.          1.3592609   3.413917\n",
      "  0.          0.          0.          0.5300188   0.          1.194633\n",
      "  1.2700082   2.101253    1.7325127   1.4464351   0.          0.38853684\n",
      "  0.          0.40229505  0.18760405  0.          8.363683    1.4078945\n",
      "  0.6481383   1.0332191   1.1459707   0.          1.8079315   2.2078846\n",
      "  0.          0.          0.          0.7068195   0.5220835   2.6270573\n",
      "  3.1953244   4.555084    1.2933677   2.1583548   0.          5.0694327\n",
      "  0.8109408   4.2367806   1.3018357   0.1868399   0.1514673   0.79911274\n",
      "  0.8575119   2.8657224   2.2463524   3.8018987   0.90640914  0.\n",
      "  0.          5.7372646   1.3996143   1.0972906   0.14687914  0.\n",
      "  0.          1.1708676   1.1226615   0.          0.          0.\n",
      "  0.          1.6114771   4.0756607   0.7705127   2.8594582   1.9655803\n",
      "  2.0896153   1.5818822   1.6222593   0.          0.          0.9433959\n",
      "  0.15145281  1.2888986   0.3750903   1.0480937   1.2293936   0.4560535\n",
      "  7.86997     0.5440644   1.6298652   0.7261227   1.9355966   1.1484699\n",
      "  0.          0.          3.32027     0.          0.893486    2.9418695\n",
      "  3.045847    0.3394803   0.          0.25315776  0.          0.\n",
      "  0.          0.          0.69380254  1.0222741   1.9794466   0.02951464\n",
      "  0.          0.          1.5439767   0.18924235  0.          2.5307586\n",
      "  2.753363    0.4312094   2.0236096   1.9384757   2.3508005   0.\n",
      "  1.971362    3.0506506   0.          2.4107597   4.540149    0.\n",
      "  3.7524965   0.          0.87775534  0.          2.112534    0.55983585\n",
      "  0.4086916   0.          0.          0.          5.9288015   0.7018099\n",
      "  1.3532296   0.35895383  1.9367353   5.5937057   2.0629754   0.7090136\n",
      "  0.          0.          2.258986    1.793107    2.298955    1.2455947\n",
      "  0.          0.33994132  1.8337778   0.          0.          2.1554558\n",
      "  0.7301886   0.          0.          2.2321029   1.2824888   0.\n",
      "  0.          1.3198131   0.3987639   0.37700343  0.          0.\n",
      "  0.          0.          0.          0.          0.          5.379429\n",
      "  0.          0.          0.          0.          0.46835726  0.\n",
      "  0.6022602   0.4169171   0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  1.2520462   0.          0.          0.          0.          0.\n",
      "  0.          0.68158937  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          1.6473134   0.8588091\n",
      "  1.6901532   0.          0.58404505  1.4523592   0.13284433  3.0093598\n",
      "  0.          2.0115838   0.13866958  0.          1.535982    0.\n",
      "  0.35595405  0.          0.          0.07917809  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          2.294197  ]\n"
     ]
    }
   ],
   "source": [
    "    for i in range\n",
    "    img1 = imread('dog.jpg', mode='RGB')\n",
    "    img1 = imresize(img1, (224, 224))\n",
    "\n",
    "    features = sess.run(vgg.features, feed_dict={vgg.imgs: [img1]})[0]\n",
    "    print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10222 [00:00<?, ?it/s]/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if sys.path[0] == '':\n",
      "/home/aman/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n",
      "100%|██████████| 10222/10222 [1:34:25<00:00,  1.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "path = \"/home/aman/dogs/train\"\n",
    "train_dir = os.listdir( path )\n",
    "labels=pd.read_csv(\"/home/aman/dogs/labels.csv\")\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "for img_name in tqdm(train_dir):\n",
    "    y_train.append(labels[labels[\"id\"]==img_name.split(\".\")[0]][\"breed\"].values[0])\n",
    "    img1 = imread(path+\"/\"+img_name, mode='RGB')\n",
    "    img1 = imresize(img1, (224, 224))\n",
    "\n",
    "    features = sess.run(vgg.features, feed_dict={vgg.imgs: [img1]})[0]\n",
    "    X_train.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.DataFrame([y_train,X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\"y_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10212</th>\n",
       "      <th>10213</th>\n",
       "      <th>10214</th>\n",
       "      <th>10215</th>\n",
       "      <th>10216</th>\n",
       "      <th>10217</th>\n",
       "      <th>10218</th>\n",
       "      <th>10219</th>\n",
       "      <th>10220</th>\n",
       "      <th>10221</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>italian_greyhound</td>\n",
       "      <td>bull_mastiff</td>\n",
       "      <td>mexican_hairless</td>\n",
       "      <td>otterhound</td>\n",
       "      <td>siberian_husky</td>\n",
       "      <td>great_dane</td>\n",
       "      <td>chihuahua</td>\n",
       "      <td>chow</td>\n",
       "      <td>chow</td>\n",
       "      <td>basset</td>\n",
       "      <td>...</td>\n",
       "      <td>boston_bull</td>\n",
       "      <td>standard_poodle</td>\n",
       "      <td>toy_terrier</td>\n",
       "      <td>boston_bull</td>\n",
       "      <td>bluetick</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>beagle</td>\n",
       "      <td>basset</td>\n",
       "      <td>affenpinscher</td>\n",
       "      <td>border_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 3.9191859, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.15766165, 0.0, 0.245042...</td>\n",
       "      <td>[0.8450592, 0.0, 0.0, 0.0, 0.8152881, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.14930806, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 1.2539288, 0.43686587, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.75247324, 0.0, 0.0, 1.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.147...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.28733414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.620...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.40800777, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4230393,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.029339738, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0118191,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03939429...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1443777,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05534098...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 10222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0      \\\n",
       "0                                  italian_greyhound   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 3.9191859, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                               1      \\\n",
       "0                                       bull_mastiff   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.15766165, 0.0, 0.245042...   \n",
       "\n",
       "                                               2      \\\n",
       "0                                   mexican_hairless   \n",
       "1  [0.8450592, 0.0, 0.0, 0.0, 0.8152881, 0.0, 0.0...   \n",
       "\n",
       "                                               3      \\\n",
       "0                                         otterhound   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               4      \\\n",
       "0                                     siberian_husky   \n",
       "1  [0.0, 0.0, 0.14930806, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                               5      \\\n",
       "0                                         great_dane   \n",
       "1  [0.0, 0.0, 1.2539288, 0.43686587, 0.0, 0.0, 0....   \n",
       "\n",
       "                                               6      \\\n",
       "0                                          chihuahua   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.75247324, 0.0, 0.0, 1.0...   \n",
       "\n",
       "                                               7      \\\n",
       "0                                               chow   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.147...   \n",
       "\n",
       "                                               8      \\\n",
       "0                                               chow   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               9      \\\n",
       "0                                             basset   \n",
       "1  [0.28733414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "\n",
       "                                               10212  \\\n",
       "0                                        boston_bull   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               10213  \\\n",
       "0                                    standard_poodle   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.620...   \n",
       "\n",
       "                                               10214  \\\n",
       "0                                        toy_terrier   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.40800777, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                               10215  \\\n",
       "0                                        boston_bull   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4230393,...   \n",
       "\n",
       "                                               10216  \\\n",
       "0                                           bluetick   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.029339738, 0.0, 0.0, 0....   \n",
       "\n",
       "                                               10217  \\\n",
       "0                                      affenpinscher   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0118191,...   \n",
       "\n",
       "                                               10218  \\\n",
       "0                                             beagle   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                               10219  \\\n",
       "0                                             basset   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03939429...   \n",
       "\n",
       "                                               10220  \\\n",
       "0                                      affenpinscher   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.1443777,...   \n",
       "\n",
       "                                               10221  \n",
       "0                                     border_terrier  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05534098...  \n",
       "\n",
       "[2 rows x 10222 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(X_train)).to_csv(\"x_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
